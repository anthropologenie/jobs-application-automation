# SimpleJobScorer - Usage Guide

## Overview
The `SimpleJobScorer` class is an AI-powered job matching engine that evaluates job postings against your resume configuration and calculates a match score (0-100).

## Features

‚úÖ **Skills Matching** (40% weight)
- Matches 59 skills from your resume
- Critical skills weighted 8-10
- High-value skills weighted 6-7
- Nice-to-have skills weighted 4-5

‚úÖ **Red Flag Detection** (10% weight, negative)
- Frontend/UI technologies (Cypress, React, Angular)
- Consultancy signals (Client Placement, Third Party, Bench Sales)
- Manual testing only roles
- Outdated technologies

‚úÖ **Domain Matching** (20% weight)
- AI/ML Testing, LLM Validation
- Data Quality, ETL/DWH
- Analytics QA, Data Engineering

‚úÖ **Location Scoring** (10% weight)
- Remote = 100 points
- Hybrid = 50 points
- Onsite = 0 points

‚úÖ **Experience Matching** (20% weight)
- Compares job requirements with your 7 years experience
- Handles ranges (5-8 years) and minimums (3+ years)

## Installation

```bash
# Ensure you have the configuration file
ls data/resume_config.json

# The scorer is ready to use
python3 scrapers/simple_scorer.py
```

## Quick Start

### Method 1: Command Line Testing

```bash
cd /home/katte/projects/jobs-application-automation
python3 scrapers/simple_scorer.py
```

This runs the built-in test suite with 3 sample jobs.

### Method 2: Python Script

```python
from scrapers.simple_scorer import SimpleJobScorer

# Initialize scorer
scorer = SimpleJobScorer(config_path="data/resume_config.json")

# Prepare job data
job_data = {
    'title': 'Senior Data QA Engineer',
    'description': '''
        We need a Data QA Engineer to validate ETL pipelines,
        test Snowflake data warehouse, write SQL queries for
        data validation, and automate testing with Python.
        Experience with AWS required.
    ''',
    'location': 'Remote',
    'company': 'DataTech AI',
    'tags': 'SQL, Python, AWS, ETL, Snowflake',
    'experience_required': '5-8 years'
}

# Score the job
result = scorer.score_job(job_data)

# Access results
print(f"Score: {result['final_score']}")
print(f"Classification: {result['classification']}")
print(f"Recommendation: {result['recommendation']}")
print(f"Should auto-import: {result['should_auto_import']}")

# Detailed breakdown
print("\nSkills matched:", len(result['matched_skills']))
for skill in result['matched_skills'][:5]:
    print(f"  - {skill['skill']} (weight: {skill['weight']})")

print("\nDomains matched:", len(result['matched_domains']))
for domain in result['matched_domains']:
    print(f"  - {domain['domain']} (weight: {domain['weight']})")

if result['red_flags']:
    print("\nRed flags found:")
    for flag in result['red_flags']:
        print(f"  - {flag['flag']} (penalty: {flag['penalty']})")
```

### Method 3: Interactive Python Session

```python
>>> from scrapers.simple_scorer import SimpleJobScorer
>>> scorer = SimpleJobScorer()

>>> job = {
...     'title': 'ETL Test Lead',
...     'description': 'Testing data pipelines with SQL and Python',
...     'location': 'Remote'
... }

>>> result = scorer.score_job(job)
>>> print(result['final_score'])
65.2
>>> print(result['recommendation'])
‚ö†Ô∏è REVIEW CAREFULLY - Consider applying (65.2%)
```

## API Reference

### SimpleJobScorer Class

#### Constructor
```python
SimpleJobScorer(config_path: str = "data/resume_config.json")
```
- **config_path**: Path to resume configuration JSON file
- **Raises**: FileNotFoundError, json.JSONDecodeError

#### Main Method: score_job()
```python
score_job(job_data: Dict) -> Dict
```

**Input: job_data dictionary**
- `title` (required): Job title string
- `description` (required): Full job description
- `location` (optional): Location string
- `company` (optional): Company name
- `tags` (optional): Comma-separated skill tags
- `experience_required` (optional): Experience requirement (e.g., "5-8 years")

**Output: Result dictionary**
```python
{
    'final_score': 68.0,                    # 0-100 score
    'classification': 'MEDIUM_FIT',         # EXCELLENT, HIGH_FIT, MEDIUM_FIT, LOW_FIT, NO_FIT
    'recommendation': '‚ö†Ô∏è REVIEW CAREFULLY - Consider applying (68.0%)',
    'should_auto_import': False,            # True if score >= 75
    'breakdown': {
        'skills_score': 71.0,
        'experience_score': 100.0,
        'domain_score': 48.0,
        'location_score': 100.0,
        'red_flag_penalty': 0.0
    },
    'matched_skills': [
        {'skill': 'SQL', 'weight': 10},
        {'skill': 'Python', 'weight': 9},
        # ... more skills
    ],
    'matched_domains': [
        {'domain': 'Data Quality', 'weight': 8},
        # ... more domains
    ],
    'red_flags': [
        {'flag': 'Cypress', 'penalty': -15},
        # ... more flags
    ],
    'job_info': {
        'title': 'Senior Data QA Engineer',
        'company': 'DataTech AI',
        'location': 'Remote'
    }
}
```

#### Helper Methods

```python
# Calculate individual component scores
skills_score, matched_skills = scorer.calculate_skills_score(job_text)
penalty, red_flags = scorer.calculate_red_flags(job_text)
domain_score, domains = scorer.calculate_domain_score(job_text)
location_score = scorer.calculate_location_score(location)
exp_score = scorer.calculate_experience_score("5-8 years", 7)

# Normalize text
clean_text = scorer.normalize_text("  Mixed CASE  text  ")
# Returns: "mixed case text"
```

## Score Classifications

| Score Range | Classification | Auto-Import | Recommendation |
|-------------|----------------|-------------|----------------|
| 85-100 | EXCELLENT | ‚úÖ Yes | üéØ Apply immediately |
| 75-84 | HIGH_FIT | ‚úÖ Yes | ‚úÖ Apply today |
| 65-74 | MEDIUM_FIT | ‚ùå No | ‚ö†Ô∏è Review carefully |
| 40-64 | LOW_FIT | ‚ùå No | ‚ùå Weak match |
| 0-39 | NO_FIT | ‚ùå No | üö´ Skip |

## Scoring Formula

```
Final Score = (Skills √ó 40%) + (Experience √ó 20%) + (Domain √ó 20%)
              + (Location √ó 10%) + (Red Flags √ó 10%)
```

### Component Score Calculations

**1. Skills Score (0-100)**
```python
# Sum weights of matched skills
total_weight = sum(weight for skill, weight in matched_skills)
# Normalize (max possible = 100 points)
skills_score = min(100, (total_weight / 100) * 100)
```

**2. Experience Score (0-100)**
- Within range: 100
- Overqualified (1-2 years): 80
- Overqualified (>2 years): 60
- Underqualified (1 year): 70
- Underqualified (>1 year): 40

**3. Domain Score (0-100)**
```python
# Sum weights of matched domains
total_weight = sum(weight for domain, weight in matched_domains)
# Normalize (max possible = 50 points)
domain_score = min(100, (total_weight / 50) * 100)
```

**4. Location Score (0-100)**
- Remote: 100
- Hybrid: 50
- Onsite: 0

**5. Red Flag Penalty (-50 to 0)**
```python
# Sum all negative weights (capped at -50)
penalty = max(-50, sum(penalty for flag, penalty in red_flags))
```

## Real-World Examples

### Example 1: Ideal Data QA Job

**Job Description:**
> Senior Data QA Engineer needed for ETL testing. Must have SQL, Python, AWS, Snowflake experience. Will test data pipelines and ensure data quality in our analytics platform. Remote position.

**Expected Results:**
- Skills Score: 70-80 (SQL, Python, AWS, Snowflake, Data Quality, Test Automation)
- Experience Score: 100 (7 years matches 5-8 range)
- Domain Score: 60-80 (ETL/DWH, Data Quality, Analytics QA)
- Location Score: 100 (Remote)
- Red Flags: 0
- **Final Score: 75-85 (HIGH_FIT or EXCELLENT)**

### Example 2: Frontend Testing Job

**Job Description:**
> QA Engineer for React testing using Cypress. Frontend testing experience required. Will test UI components and write Cypress automation tests.

**Expected Results:**
- Skills Score: 0 (No critical skills matched)
- Experience Score: 80-100
- Domain Score: 0
- Location Score: 0-50
- Red Flags: -50 (Cypress -15, React -15, Frontend -12)
- **Final Score: 10-20 (NO_FIT)**

### Example 3: Consultancy/Body Shopping

**Job Description:**
> QA Engineers needed for client placement. Third party projects. Multiple clients. Onsite at client location.

**Expected Results:**
- Skills Score: 0
- Experience Score: 100
- Domain Score: 0
- Location Score: 0
- Red Flags: -50 (Client Placement -20, Third Party -20)
- **Final Score: 15-20 (NO_FIT)**

## Integration with Job Scraping Pipeline

### Step 1: Scrape Jobs
```python
# (To be implemented)
jobs = scrape_linkedin(keywords=['Data QA', 'ETL Testing'])
```

### Step 2: Score Jobs
```python
scorer = SimpleJobScorer()
scored_jobs = []

for job in jobs:
    result = scorer.score_job(job)
    scored_jobs.append(result)
```

### Step 3: Filter and Auto-Import
```python
# Auto-import high-scoring jobs (>= 75)
high_fit_jobs = [j for j in scored_jobs if j['should_auto_import']]

# Store in database
for job in high_fit_jobs:
    db.execute("""
        INSERT INTO opportunities (company, role, source, match_score)
        VALUES (?, ?, 'LinkedIn', ?)
    """, (job['job_info']['company'], job['job_info']['title'], job['final_score']))
```

### Step 4: Display on Dashboard
```python
# Show jobs sorted by score
sorted_jobs = sorted(scored_jobs, key=lambda x: x['final_score'], reverse=True)

for job in sorted_jobs[:10]:  # Top 10
    print(f"{job['final_score']:.1f} - {job['job_info']['title']} at {job['job_info']['company']}")
    print(f"   {job['recommendation']}")
```

## Customization

### Adjust Scoring Weights

Edit `data/resume_config.json`:

```json
"scoring_weights": {
  "skills_match": 0.50,      // Increase skills importance
  "experience_match": 0.15,  // Decrease experience importance
  "domain_match": 0.20,
  "location_match": 0.10,
  "red_flags": 0.05          // Reduce red flag impact
}
```

### Add New Skills

```json
"skills": {
  "critical": {
    "items": {
      "SQL": 10,
      "New Skill": 9  // Add here
    }
  }
}
```

### Add Red Flags

```json
"red_flags": {
  "deal_breakers": {
    "items": {
      "New Red Flag": -15  // Add here
    }
  }
}
```

## Error Handling

The scorer handles common errors gracefully:

```python
try:
    scorer = SimpleJobScorer("invalid/path.json")
except FileNotFoundError as e:
    print(f"Config file not found: {e}")

try:
    result = scorer.score_job({})  # Missing required fields
except ValueError as e:
    print(f"Invalid job data: {e}")

try:
    scorer = SimpleJobScorer("malformed.json")
except json.JSONDecodeError as e:
    print(f"Invalid JSON: {e}")
```

## Logging

The scorer uses Python's logging module:

```python
import logging

# Enable debug logging
logging.basicConfig(level=logging.DEBUG)

scorer = SimpleJobScorer()
# Will log: Loaded 59 skills, 36 red flags, 18 domains

result = scorer.score_job(job_data)
# Will log: Skills matched: 8, Total weight: 71, Normalized: 71.0
```

## Testing

Run the built-in test suite:

```bash
python3 scrapers/simple_scorer.py
```

This will test 3 scenarios:
1. ‚úÖ Excellent Data QA job (should score 65-80)
2. ‚ùå Frontend React job (should score <30 with red flags)
3. ‚ùå Consultancy role (should score <20 with heavy penalties)

## Performance

- **Initialization**: ~10ms (load config)
- **Scoring**: ~5-10ms per job
- **Throughput**: ~100-200 jobs/second

Suitable for scoring 1000s of jobs in batch processing.

## Troubleshooting

### Issue: Low scores for good jobs
**Solution**: Add more synonyms to `keyword_synonyms` in config

### Issue: Red flags too strict
**Solution**: Reduce penalty values or adjust `red_flags` weight

### Issue: Skills not matching
**Solution**: Check for exact text matching with word boundaries

## Next Steps

1. ‚úÖ Scorer implemented and tested
2. ‚è≥ Integrate with job scraping (LinkedIn, Naukri, Indeed)
3. ‚è≥ Store scored jobs in database (scraped_jobs_archive table)
4. ‚è≥ Display on dashboard "Job Matches" tab
5. ‚è≥ Auto-import jobs with score >= 75

---

**Version**: 1.0.0  
**Created**: 2025-11-14  
**Author**: Karthik Shetty
